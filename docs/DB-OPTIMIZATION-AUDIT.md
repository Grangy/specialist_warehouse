# Аудит: оптимизация работы с БД и логами

На основе анализа логов продакшена (specialist-warehouse) и кода API.

---

## 1. Что видно по логам

### 1.1. Избыточное логирование

| Источник | Что пишется | Частота |
|----------|-------------|---------|
| `[API Auth] Используем авторизацию через cookies` | middleware + route | **На каждый запрос**, нередко по 2–4 раза на один сценарий (несколько вызовов requireAuth) |
| `[API] Найдено заказов в БД: N, фильтр...` | GET /api/shipments | На каждый запрос списка заказов (частый поллинг у нескольких пользователей) |
| `[API Confirm]` (много строк) | POST confirm | Десятки строк на одно подтверждение заказа |
| `[save-progress] Обновляем позицию УТ-...` | POST save-progress | **По одной строке на каждую позицию** (20 позиций → 20+ строк). В логах видно дублирование — один и тот же набор позиций логируется дважды за один запрос |
| `[save-confirmation-progress] Обновляем позицию...` | POST save-confirmation-progress | Аналогично — по строке на позицию |
| `[Ready-For-Export]` / ответ 1С | ready-for-export, sync-1c | **Полный JSON ответа** с `orders[].lines_summary[]` (sku, qty, collected_qty) — сотни строк на один запрос |

Итог: при активной работе (несколько checker/collector, поллинг списка, сохранение прогресса, выгрузка в 1С) логи быстро разрастаются, сложно искать ошибки, растёт I/O и объём хранения логов.

### 1.2. Повторяющиеся запросы к БД

- Один и тот же сценарий: «Найдено заказов в БД: 91» → затем 89 → 89 → 88 — список заказов запрашивается очень часто разными клиентами (поллинг).
- На один запрос списка заказов выполняется тяжёлый запрос с `include` (shipments → tasks → lines и т.д.) и отдельная батч-загрузка locks по taskId.

### 1.3. Много мелких записей в БД в одном запросе

- **save-progress**: в цикле по каждой позиции задания вызывается отдельно `prisma.shipmentTaskLine.update()`. Для задания из 20 позиций — 20 последовательных UPDATE.
- **save-confirmation-progress**: то же — по одному `update()` на позицию.
- После всех обновлений в save-progress делается ещё один `findUnique` по заданию с `include` (lines + shipmentLine), чтобы вернуть прогресс — то есть дополнительный круг по БД.

---

## 2. Анализ по направлениям

### 2.1. Логирование

**Проблемы:**

1. В проде в stdout пишется то же, что и в разработке: отладочные сообщения (`[API Auth]`, `[API Confirm]`, построчные `[save-progress]`), плюс полные тела ответов (Ready-For-Export, Sync-1C).
2. Нет уровней (info/debug): нельзя в проде отключить шум, оставив только ошибки и важные события.
3. Дублирование: один и тот же save-progress даёт два прохода по позициям с одинаковым логированием (по коду — один цикл; дубль в логах может быть из-за повторного запроса с фронта или двойного вызова).

**Рекомендации:**

- Ввести уровень логирования (например, `DEBUG_API=1` или `LOG_LEVEL=debug`) и в проде по умолчанию не писать:
  - `[API Auth]` на каждый запрос;
  - `[API] Найдено заказов...`;
  - все строки `[API Confirm]` и `[save-progress]` / `[save-confirmation-progress]` по каждой позиции;
  - полный JSON ответов Ready-For-Export / Sync-1C.
- Оставить в info: ошибки, факт подтверждения заказа (номер, пользователь), факт выгрузки в 1С (количество заказов), критические события.
- Полный JSON и детальный аудит — только при `LOG_LEVEL=debug` или отдельном флаге для 1С (например, только для отладки интеграции).

**Ожидаемый эффект:** объём логов в проде можно снизить в разы (на 70–90% при текущей нагрузке), проще искать ошибки и хранить логи.

---

### 2.2. Запросы к БД: save-progress и save-confirmation-progress

**Проблемы:**

1. В **save-progress** для задания с N позициями выполняется N раз `prisma.shipmentTaskLine.update()` в цикле — N отдельных round-trip к БД.
2. В **save-confirmation-progress** — та же схема.
3. В save-progress после цикла — ещё один `findUnique` по заданию с вложенными `lines` и `shipmentLine`, только чтобы посчитать `collectedItems` и вернуть progress. Данные для счёта уже есть в `task.lines` после обновлений, но текущая реализация не переиспользует их.

**Рекомендации:**

1. **Батч обновлений в одной транзакции:**
   - Обернуть все `update` по позициям в `prisma.$transaction([...])` (массив из N вызовов `prisma.shipmentTaskLine.update`).
   - Или один раз прочитать задание, в цикле подготовить массив обновлений, затем выполнить их в одной транзакции.
   - Эффект: вместо N отдельных коммитов — один коммит, меньше накладных расходов и блокировок SQLite.

2. **Убрать лишний findUnique после save-progress:**
   - Считать `collectedItems` и `totalItems` по уже загруженному `task.lines`, применяя к ним «виртуальные» значения из `lines` (collectedQty, checked) так, как они будут записаны, и вернуть этот прогресс без повторного чтения задания из БД.
   - Эффект: минус один тяжёлый read с include на каждый save-progress.

**Ожидаемый эффект:** для задания из 20 позиций — с ~21 обращений к БД (20 update + 1 findUnique) до 1 транзакции + 0 лишних read. Ускорение запроса save-progress примерно в 2–5 раз (зависит от диска и нагрузки).

---

### 2.3. GET /api/shipments (список заказов)

**Проблемы:**

1. Запрос тяжёлый: заказы с вложенными tasks, lines, регионами, приоритетами; отдельно батчами подгружаются locks.
2. Частота вызова высокая: несколько пользователей (checker, collector, admin) обновляют список по таймеру — видны повторяющиеся «Найдено заказов в БД: 89/88...».
3. Каждый запрос полностью пересобирает ответ; кэша нет.

**Рекомендации:**

1. **Кэш на короткое время (например, 5–15 сек):**
   - Ключ: `status` (или роль + статус), значение: последний ответ + время.
   - При запросе с теми же параметрами отдавать кэш, если не старше порога; иначе — запрос в БД и обновление кэша.
   - Инвалидация: при любом изменении заказов/заданий (confirm, save-progress, lock, создание заказа и т.д.) сбрасывать кэш для затронутых фильтров.
   - Осторожно: при нескольких инстансах приложения нужен либо общий кэш (Redis), либо кэш только при одном процессе.

2. **Уменьшить объём данных в ответе:**
   - Не отдавать лишние поля в include (например, часть полей lines), если фронт ими не пользуется.
   - Рассмотреть пагинацию или ограничение по дате/количеству для списка.

3. **Увеличить интервал поллинга на фронте** (где возможно) — например, с 5 до 10–15 сек для вкладки со списком, чтобы снизить число идентичных запросов.

**Ожидаемый эффект:** при 5–10 активных пользователях и поллинге раз в 5 сек число тяжёлых запросов к БД можно снизить на 50–80% за счёт кэша; время отклика для повторных запросов — с сотен миллисекунд до единиц мс (из кэша).

---

### 2.4. Ready-For-Export и Sync-1C

**Проблемы:**

1. В лог пишется полный JSON ответа с массивом заказов и `lines_summary` — при большом количестве заказов и позиций лог раздувается на сотни строк на один запрос.
2. Запрос к БД один раз за выборку готовых заказов — сам по себе не обязательно неоптимален, но при частых вызовах 1С нагрузка растёт.

**Рекомендации:**

1. Не логировать полное тело ответа в info. Оставить одну строку вида: «Ready-For-Export: отдано N заказов, requestId=...». Полный JSON — только при debug.
2. При необходимости ограничить частоту вызовов со стороны 1С (rate limit или предупреждение в документации).

**Ожидаемый эффект:** сильное сокращение размера логов при выгрузках в 1С (на порядок для типичного ответа).

---

### 2.5. Prisma и SQLite

**Текущее:** в проде `log: ['error']` — запросы не логируются; в dev — `['query', 'error', 'warn']`.

**Рекомендации:**

1. Оставить в проде только `error` (или добавить `warn` при необходимости).
2. Для SQLite при высокой конкуренции за запись рассмотреть:
   - `connection_limit: 1` (уже по сути при одном процессе) и минимизацию длинных транзакций;
   - WAL и настройки checkpoint при росте БД.

**Ожидаемый эффект:** стабильность под нагрузкой, меньше риска locked DB при батчировании обновлений в транзакциях.

---

## 3. Сводная таблица

| Направление | Действие | Ожидаемый результат |
|-------------|---------|----------------------|
| Логи | Убрать/снизить уровень отладочных логов в проде; не логировать полный JSON ответов 1С | Снижение объёма логов на 70–90%, удобнее разбор инцидентов |
| save-progress / save-confirmation-progress | Батч обновлений в одной транзакции; убрать лишний findUnique после save-progress | Ускорение сохранения прогресса в 2–5 раз, меньше обращений к БД |
| GET /api/shipments | Краткосрочный кэш + инвалидация при изменениях; при возможности реже поллинг на фронте | Снижение числа тяжёлых запросов на 50–80%, быстрее ответ из кэша |
| Ready-For-Export / Sync-1C | Логировать только сводку (N заказов), не тело ответа | Резкое сокращение логов при выгрузках в 1С |
| Общее | Уровни логирования (LOG_LEVEL), в проде по умолчанию info без debug-шума | Предсказуемый объём логов и производительность I/O |

---

## 4. Приоритеты внедрения

1. **Высокий (быстро, мало риска):** сокращение логов в проде (уровни, убрать полный JSON и построчный save-progress/save-confirmation). Эффект сразу виден в логах и размере файлов.
2. **Высокий (средний объём работ):** батч обновлений в транзакции в save-progress и save-confirmation-progress + отказ от лишнего findUnique. Сильно снижает нагрузку на БД при частом сохранении прогресса.
3. **Средний:** кэш для GET /api/shipments с аккуратной инвалидацией. Требует продуманной схемы сброса кэша при изменениях.
4. **Низкий:** тонкая настройка SQLite (WAL, checkpoint) при росте размера БД и числа конкурентных записей.

Документ подготовлен только в виде анализа; изменения в коде не вносились.
